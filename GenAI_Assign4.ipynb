{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3332511",
   "metadata": {},
   "source": [
    "# Question-Answering Chatbot using Pre-trained Language Model\n",
    "\n",
    "This notebook demonstrates a simple QA chatbot using Hugging Face's transformers library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b06e18",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5a68f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ltk (C:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ltk (C:\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: transformers in c:\\python312\\lib\\site-packages (4.49.0)\n",
      "Requirement already satisfied: torch in c:\\python312\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\python312\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\python312\\lib\\site-packages (from transformers) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\samarth\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python312\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\python312\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\python312\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\python312\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\python312\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\python312\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\samarth\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: networkx in c:\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\python312\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\python312\\lib\\site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\samarth\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\samarth\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\samarth\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install transformers torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b81c0e",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67e337c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading QA model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load pre-trained question-answering model\n",
    "# Using distilbert-base-cased-distilled-squad - a smaller, faster model fine-tuned on SQuAD dataset\n",
    "print(\"Loading QA model...\")\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\", framework=\"pt\")\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df62da77",
   "metadata": {},
   "source": [
    "## Step 3: Define the Context\n",
    "\n",
    "The chatbot needs a context (knowledge base) to answer questions from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79836077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context loaded successfully!\n",
      "Context length: 889 characters\n"
     ]
    }
   ],
   "source": [
    "# Sample context about AI and Machine Learning\n",
    "context = \"\"\"\n",
    "Artificial Intelligence (AI) is the simulation of human intelligence processes by machines, \n",
    "especially computer systems. These processes include learning, reasoning, and self-correction. \n",
    "Machine Learning is a subset of AI that provides systems the ability to automatically learn \n",
    "and improve from experience without being explicitly programmed. Deep Learning is a subset \n",
    "of machine learning that uses neural networks with multiple layers. The field of AI was \n",
    "founded in 1956 at a conference at Dartmouth College. AI applications include expert systems, \n",
    "natural language processing, speech recognition, and computer vision. Python is one of the \n",
    "most popular programming languages for AI and machine learning development. TensorFlow and \n",
    "PyTorch are popular frameworks for building deep learning models. Neural networks are inspired \n",
    "by the structure and function of the human brain.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Context loaded successfully!\")\n",
    "print(f\"Context length: {len(context)} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3d85b3",
   "metadata": {},
   "source": [
    "## Step 4: Test with Sample Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c23eaf0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing QA Chatbot:\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Q: What is Artificial Intelligence?\n",
      "A: the simulation of human intelligence processes by machines\n",
      "   (Confidence: 0.3144)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Q: When was AI founded?\n",
      "A: 1956\n",
      "   (Confidence: 0.9923)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Q: What programming language is popular for AI?\n",
      "A: Python\n",
      "   (Confidence: 0.9878)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Q: What are some AI frameworks?\n",
      "A: TensorFlow and \n",
      "PyTorch\n",
      "   (Confidence: 0.9875)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Q: What is Machine Learning?\n",
      "A: provides systems the ability to automatically learn \n",
      "and improve from experience without being explicitly programmed\n",
      "   (Confidence: 0.0974)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test questions\n",
    "test_questions = [\n",
    "    \"What is Artificial Intelligence?\",\n",
    "    \"When was AI founded?\",\n",
    "    \"What programming language is popular for AI?\",\n",
    "    \"What are some AI frameworks?\",\n",
    "    \"What is Machine Learning?\"\n",
    "]\n",
    "\n",
    "print(\"Testing QA Chatbot:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for question in test_questions:\n",
    "    result = qa_pipeline(question=question, context=context)\n",
    "    print(f\"\\nQ: {question}\")\n",
    "    print(f\"A: {result['answer']}\")\n",
    "    print(f\"   (Confidence: {result['score']:.4f})\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9757726",
   "metadata": {},
   "source": [
    "## Step 5: Create Interactive Chatbot Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9681ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA Chatbot Function Created!\n",
      "\n",
      "Example usage:\n",
      "Answer: a subset \n",
      "of machine learning that uses neural networks with multiple layers\n",
      "Confidence: 0.5137\n"
     ]
    }
   ],
   "source": [
    "def qa_chatbot(question, context, min_confidence=0.01):\n",
    "    \"\"\"\n",
    "    Simple QA chatbot function\n",
    "    \n",
    "    Args:\n",
    "        question: User's question\n",
    "        context: Context/knowledge base to answer from\n",
    "        min_confidence: Minimum confidence threshold (default: 0.01)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with answer and confidence score\n",
    "    \"\"\"\n",
    "    result = qa_pipeline(question=question, context=context)\n",
    "    \n",
    "    if result['score'] >= min_confidence:\n",
    "        return {\n",
    "            'answer': result['answer'],\n",
    "            'confidence': result['score'],\n",
    "            'status': 'success'\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            'answer': \"I'm not confident enough to answer this question based on the given context.\",\n",
    "            'confidence': result['score'],\n",
    "            'status': 'low_confidence'\n",
    "        }\n",
    "\n",
    "# Test the chatbot function\n",
    "print(\"QA Chatbot Function Created!\")\n",
    "print(\"\\nExample usage:\")\n",
    "response = qa_chatbot(\"What is Deep Learning?\", context)\n",
    "print(f\"Answer: {response['answer']}\")\n",
    "print(f\"Confidence: {response['confidence']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c94c868",
   "metadata": {},
   "source": [
    "## Step 6: Interactive Chat Loop (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e0de1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Q: more detailed\n",
      "================================================================================\n",
      "\n",
      "A: simulation of human intelligence processes by machines\n",
      "Confidence: 0.1626\n",
      "Status: success\n",
      "================================================================================\n",
      "\n",
      "ðŸ’¡ Tip: Change 'your_question' above and run this cell again!\n"
     ]
    }
   ],
   "source": [
    "# Interactive Q&A - Just change the question below and run this cell!\n",
    "# You can run this cell multiple times with different questions\n",
    "\n",
    "your_question = \"What is Deep Learning?\" \n",
    " \n",
    "print(\"=\"*80)\n",
    "print(f\"Q: {your_question}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "response = qa_chatbot(your_question, context)\n",
    "print(f\"\\nA: {response['answer']}\")\n",
    "print(f\"Confidence: {response['confidence']:.4f}\")\n",
    "print(f\"Status: {response['status']}\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nðŸ’¡ Tip: Change 'your_question' above and run this cell again!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddac041",
   "metadata": {},
   "source": [
    "## Additional Features & Enhancements\n",
    "\n",
    "You can enhance this chatbot by:\n",
    "- Adding multiple contexts or documents\n",
    "- Implementing conversation history\n",
    "- Using more advanced models (GPT, BERT-large, etc.)\n",
    "- Adding web scraping to get real-time information\n",
    "- Creating a GUI with gradio or streamlit\n",
    "- Implementing semantic search for better context retrieval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
